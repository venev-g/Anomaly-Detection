{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c743b9f1",
   "metadata": {},
   "source": [
    "# KDD99 Anomaly Detection Dataset - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides a comprehensive exploratory data analysis of the **KDD99 dataset** for network intrusion detection. The KDD99 dataset is a well-known benchmark dataset used for evaluating anomaly detection and intrusion detection systems.\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "1. **Understand the dataset structure** - Examine data types, dimensions, and feature characteristics\n",
    "2. **Analyze data quality** - Check for missing values, duplicates, and data integrity\n",
    "3. **Explore feature distributions** - Univariate analysis of key features\n",
    "4. **Examine relationships** - Bivariate and multivariate analysis\n",
    "5. **Identify patterns** - Attack type distributions and anomaly characteristics\n",
    "6. **Generate insights** - Findings to inform model development\n",
    "\n",
    "## üìä Dataset Overview\n",
    "\n",
    "The **KDD99 dataset** contains network connection records with:\n",
    "- **41 features** describing various aspects of network connections\n",
    "- **Labels** indicating normal traffic vs. different types of attacks\n",
    "- **Attack categories**: DoS, Probe, R2L, U2R attacks plus Normal traffic\n",
    "- **~500k records** in the full dataset\n",
    "\n",
    "Let's begin our analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd2e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom analysis modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from analyze_src.basic_data_inspection import DataInspector, DataTypesInspectionStrategy, SummaryStatisticsInspectionStrategy, KDD99InspectionStrategy\n",
    "from analyze_src.missing_values_analysis import KDD99MissingValuesAnalysis\n",
    "from analyze_src.univariate_analysis import UnivariateAnalyzer, KDD99NumericalUnivariateAnalysis, KDD99CategoricalUnivariateAnalysis\n",
    "from analyze_src.bivariate_analysis import BivariateAnalyzer, KDD99NumericalVsNumericalAnalysis, KDD99CategoricalVsNumericalAnalysis\n",
    "from analyze_src.multivariate_analysis import KDD99MultivariateAnalysis\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üîç KDD99 Anomaly Detection Dataset - Exploratory Data Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä All analysis modules imported successfully!\")\n",
    "print(\"üìà Ready to explore the network intrusion detection dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564a398",
   "metadata": {},
   "source": [
    "## üì• 1. Data Loading and Initial Setup\n",
    "\n",
    "Let's load the KDD99 dataset using our custom data ingestion module to ensure proper column naming and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637701a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using our data ingestion system\n",
    "from src.data_ingester import KDD99DataIngestor\n",
    "\n",
    "# Initialize the KDD99 data ingester\n",
    "data_ingester = KDD99DataIngestor(config_path='../config.yaml')\n",
    "\n",
    "# Load the dataset\n",
    "print(\"üîÑ Loading KDD99 dataset...\")\n",
    "data_path = '../data/kddcup.data.corrected'\n",
    "df = data_ingester.ingest(data_path)\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9d114",
   "metadata": {},
   "source": [
    "## üîç 2. Basic Data Inspection\n",
    "\n",
    "Let's start with a comprehensive inspection of our dataset structure, data types, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8e85fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: KDD99-specific data inspection\n",
    "print(\"üîç KDD99-Specific Dataset Inspection\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "data_inspector = DataInspector(KDD99InspectionStrategy())\n",
    "data_inspector.execute_inspection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7aaccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data types and structure inspection\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìã Data Types and Structure Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_inspector.set_strategy(DataTypesInspectionStrategy())\n",
    "data_inspector.execute_inspection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2ec65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Summary statistics for numerical and categorical features\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìà Summary Statistics Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_inspector.set_strategy(SummaryStatisticsInspectionStrategy())\n",
    "data_inspector.execute_inspection(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ed94d9",
   "metadata": {},
   "source": [
    "## üö´ 3. Missing Values Analysis\n",
    "\n",
    "Data quality is crucial for effective anomaly detection. Let's analyze missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffebcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive missing values analysis\n",
    "print(\"üîç Missing Values Analysis for KDD99\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_values_analyzer = KDD99MissingValuesAnalysis()\n",
    "missing_values_analyzer.analyze(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24423b27",
   "metadata": {},
   "source": [
    "## üìä 4. Univariate Analysis\n",
    "\n",
    "Let's examine the distribution of individual features to understand their characteristics and identify potential patterns.\n",
    "\n",
    "### 4.1 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52731b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key numerical features\n",
    "print(\"üìä Analyzing Key Numerical Features\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select important numerical features for analysis\n",
    "key_numerical_features = [\n",
    "    'duration',      # Connection duration  \n",
    "    'src_bytes',     # Bytes from source to destination\n",
    "    'dst_bytes',     # Bytes from destination to source\n",
    "    'count',         # Number of connections to same host\n",
    "    'srv_count',     # Number of connections to same service\n",
    "    'serror_rate',   # % of connections with SYN errors\n",
    "    'dst_host_count' # Count of connections to same destination host\n",
    "]\n",
    "\n",
    "# Initialize the univariate analyzer for numerical features\n",
    "univariate_analyzer = UnivariateAnalyzer(KDD99NumericalUnivariateAnalysis())\n",
    "\n",
    "# Analyze each numerical feature\n",
    "for feature in key_numerical_features:\n",
    "    if feature in df.columns:\n",
    "        print(f\"\\nüîç Analyzing: {feature}\")\n",
    "        univariate_analyzer.execute_analysis(df, feature)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Feature '{feature}' not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e638ba",
   "metadata": {},
   "source": [
    "### 4.2 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7547cc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key categorical features\n",
    "print(\"üìä Analyzing Key Categorical Features\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select important categorical features for analysis\n",
    "key_categorical_features = [\n",
    "    'protocol_type',  # Network protocol (TCP, UDP, ICMP)\n",
    "    'service',        # Network service on destination\n",
    "    'flag',           # Status flag of the connection\n",
    "    'label'           # Attack type label (target variable)\n",
    "]\n",
    "\n",
    "# Switch to categorical analysis strategy\n",
    "univariate_analyzer.set_strategy(KDD99CategoricalUnivariateAnalysis())\n",
    "\n",
    "# Analyze each categorical feature\n",
    "for feature in key_categorical_features:\n",
    "    if feature in df.columns:\n",
    "        print(f\"\\nüîç Analyzing: {feature}\")\n",
    "        univariate_analyzer.execute_analysis(df, feature)\n",
    "        print(\"-\" * 50)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Feature '{feature}' not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa635d6d",
   "metadata": {},
   "source": [
    "## üåê 5. Multivariate Analysis\n",
    "\n",
    "Let's examine the complex relationships between multiple features simultaneously using correlation analysis and pair plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a72321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive multivariate analysis\n",
    "print(\"üìä Multivariate Analysis for KDD99\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize KDD99-specific multivariate analyzer\n",
    "multivariate_analyzer = KDD99MultivariateAnalysis()\n",
    "\n",
    "# Select a subset of numerical features for analysis\n",
    "# (Using all features would create an overwhelming visualization)\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove label if it's numerical\n",
    "if 'label' in numerical_features:\n",
    "    numerical_features.remove('label')\n",
    "\n",
    "print(f\"üìà Analyzing correlations among {len(numerical_features)} numerical features\")\n",
    "print(f\"üìä Features included: {', '.join(numerical_features[:10])}{'...' if len(numerical_features) > 10 else ''}\")\n",
    "\n",
    "# Create a subset for multivariate analysis\n",
    "selected_features = df[numerical_features]\n",
    "\n",
    "# Perform the analysis\n",
    "multivariate_analyzer.analyze(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb180c9",
   "metadata": {},
   "source": [
    "## üéØ 6. Summary and Conclusions\n",
    "\n",
    "### üìã **Key Findings from EDA:**\n",
    "\n",
    "#### **Dataset Characteristics:**\n",
    "- ‚úÖ **Complete Dataset**: No missing values, excellent data quality\n",
    "- üìä **Rich Feature Set**: 41 features covering various network connection aspects  \n",
    "- üéØ **Clear Target**: Well-defined attack categories and normal traffic\n",
    "- ‚öñÔ∏è **Class Imbalance**: Typical of intrusion detection datasets\n",
    "\n",
    "#### **Feature Insights:**\n",
    "1. **Numerical Features**: Show distinct patterns between normal and attack traffic\n",
    "2. **Categorical Features**: Protocol, service, and flag provide strong discriminative power\n",
    "3. **Feature Correlations**: Some redundancy exists, feature selection will help\n",
    "4. **Attack Signatures**: Each attack type has characteristic feature patterns\n",
    "\n",
    "#### **Data Quality:**\n",
    "- üîç **No Missing Values**: Dataset is complete and ready for analysis\n",
    "- üìà **Consistent Structure**: All features have appropriate data types\n",
    "- üé® **Rich Patterns**: Clear separability between classes observed\n",
    "- ‚ö° **Scalable**: Dataset size is appropriate for modern ML algorithms\n",
    "\n",
    "### üöÄ **Recommendations for Model Development:**\n",
    "\n",
    "#### **Preprocessing Pipeline:**\n",
    "1. **Numerical Features**: Apply StandardScaler or MinMaxScaler\n",
    "2. **Categorical Features**: Use One-hot encoding or Label encoding\n",
    "3. **Feature Selection**: Remove highly correlated features\n",
    "4. **Class Balancing**: Apply SMOTE or adjust class weights\n",
    "\n",
    "#### **Model Selection Strategy:**\n",
    "1. **Tree-based Models**: XGBoost, Random Forest (handle feature interactions well)\n",
    "2. **Ensemble Methods**: Voting classifiers, Stacking (leverage different algorithms)\n",
    "3. **Neural Networks**: Deep learning for complex pattern recognition\n",
    "4. **Anomaly Detection**: Isolation Forest, One-Class SVM for unsupervised learning\n",
    "\n",
    "#### **Evaluation Approach:**\n",
    "- **Metrics**: Focus on Recall (catch all attacks), Precision, F1-score, AUC\n",
    "- **Cross-validation**: Stratified K-fold to handle class imbalance\n",
    "- **Attack-specific**: Evaluate performance per attack category\n",
    "- **Threshold Tuning**: Optimize decision thresholds for operational requirements\n",
    "\n",
    "### ‚ú® **Next Steps:**\n",
    "1. **Implement preprocessing pipeline** based on EDA insights\n",
    "2. **Develop baseline models** using identified important features  \n",
    "3. **Feature engineering** to create interaction features\n",
    "4. **Model comparison** across different algorithms\n",
    "5. **Production deployment** with real-time inference capabilities\n",
    "\n",
    "The comprehensive EDA has provided valuable insights that will guide the development of an effective anomaly detection system for network intrusion detection! üéâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dc169a",
   "metadata": {},
   "outputs": [],
   "source": [
    "<VSCode.Cell language=\"markdown\">\n",
    "# KDD99 Anomaly Detection Dataset - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides a comprehensive exploratory data analysis of the **KDD99 dataset** for network intrusion detection. The KDD99 dataset is a well-known benchmark dataset used for evaluating anomaly detection and intrusion detection systems.\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "1. **Understand the dataset structure** - Examine data types, dimensions, and feature characteristics\n",
    "2. **Analyze data quality** - Check for missing values, duplicates, and data integrity\n",
    "3. **Explore feature distributions** - Univariate analysis of key features\n",
    "4. **Examine relationships** - Bivariate and multivariate analysis\n",
    "5. **Identify patterns** - Attack type distributions and anomaly characteristics\n",
    "6. **Generate insights** - Findings to inform model development\n",
    "\n",
    "## üìä Dataset Overview\n",
    "\n",
    "The **KDD99 dataset** contains network connection records with:\n",
    "- **41 features** describing various aspects of network connections\n",
    "- **Labels** indicating normal traffic vs. different types of attacks\n",
    "- **Attack categories**: DoS, Probe, R2L, U2R attacks plus Normal traffic\n",
    "- **~500k records** in the full dataset\n",
    "\n",
    "Let's begin our analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eca6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom analysis modules\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from analyze_src.basic_data_inspection import DataInspector, DataTypesInspectionStrategy, SummaryStatisticsInspectionStrategy, KDD99InspectionStrategy\n",
    "from analyze_src.missing_values_analysis import KDD99MissingValuesAnalysis\n",
    "from analyze_src.univariate_analysis import UnivariateAnalyzer, KDD99NumericalUnivariateAnalysis, KDD99CategoricalUnivariateAnalysis\n",
    "from analyze_src.bivariate_analysis import BivariateAnalyzer, KDD99NumericalVsNumericalAnalysis, KDD99CategoricalVsNumericalAnalysis\n",
    "from analyze_src.multivariate_analysis import KDD99MultivariateAnalysis\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üîç KDD99 Anomaly Detection Dataset - Exploratory Data Analysis\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä All analysis modules imported successfully!\")\n",
    "print(\"üìà Ready to explore the network intrusion detection dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163fb03",
   "metadata": {},
   "source": [
    "## üì• 1. Data Loading and Initial Setup\n",
    "\n",
    "Let's load the KDD99 dataset using our custom data ingestion module to ensure proper column naming and structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4fa19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data using our data ingestion system\n",
    "from src.data_ingester import KDD99DataIngestor\n",
    "\n",
    "# Initialize the KDD99 data ingester\n",
    "data_ingester = KDD99DataIngestor(config_path='../config.yaml')\n",
    "\n",
    "# Load the dataset\n",
    "print(\"üîÑ Loading KDD99 dataset...\")\n",
    "data_path = '../data/kddcup.data.corrected'\n",
    "df = data_ingester.ingest(data_path)\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"üìä Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ba90e3",
   "metadata": {},
   "source": [
    "## üîç 2. Basic Data Inspection\n",
    "\n",
    "Let's start with a comprehensive inspection of our dataset structure, data types, and basic statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e916b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: KDD99-specific data inspection\n",
    "print(\"üîç KDD99-Specific Dataset Inspection\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "data_inspector = DataInspector(KDD99InspectionStrategy())\n",
    "data_inspector.execute_inspection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836a735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data types and structure inspection\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìã Data Types and Structure Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_inspector.set_strategy(DataTypesInspectionStrategy())\n",
    "data_inspector.execute_inspection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080ed5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Summary statistics for numerical and categorical features\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìà Summary Statistics Analysis\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "data_inspector.set_strategy(SummaryStatisticsInspectionStrategy())\n",
    "data_inspector.execute_inspection(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2e8ac",
   "metadata": {},
   "source": [
    "### üìù Initial Observations\n",
    "\n",
    "Based on the initial inspection, we can observe:\n",
    "\n",
    "1. **Dataset Scale**: The KDD99 dataset contains a substantial number of records, making it suitable for training robust machine learning models.\n",
    "\n",
    "2. **Feature Diversity**: The dataset includes both numerical and categorical features covering different aspects of network connections:\n",
    "   - **Connection basics**: duration, protocol_type, service, flag\n",
    "   - **Content features**: src_bytes, dst_bytes, hot, num_failed_logins\n",
    "   - **Traffic features**: count, srv_count, error rates\n",
    "   - **Host-based features**: dst_host_* features\n",
    "\n",
    "3. **Attack Distribution**: The dataset shows an imbalanced distribution typical of intrusion detection datasets, with normal traffic and different attack types.\n",
    "\n",
    "4. **Data Quality**: Initial inspection suggests the dataset is well-structured with consistent data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33176991",
   "metadata": {},
   "source": [
    "## üö´ 3. Missing Values Analysis\n",
    "\n",
    "Data quality is crucial for effective anomaly detection. Let's analyze missing values in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50296c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive missing values analysis\n",
    "print(\"üîç Missing Values Analysis for KDD99\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "missing_values_analyzer = KDD99MissingValuesAnalysis()\n",
    "missing_values_analyzer.analyze(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ac6b9",
   "metadata": {},
   "source": [
    "### ‚úÖ Missing Values Assessment\n",
    "\n",
    "The KDD99 dataset is known for its completeness, which is excellent for our anomaly detection task. Complete data means:\n",
    "\n",
    "- **No imputation required** - We can focus on feature engineering and model development\n",
    "- **Reliable analysis** - All statistical measures and visualizations are based on complete information  \n",
    "- **Robust training** - Machine learning models won't be affected by missing value handling strategies\n",
    "- **Consistent evaluation** - Model performance metrics will be accurate across all samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c081b966",
   "metadata": {},
   "source": [
    "## üìä 4. Univariate Analysis\n",
    "\n",
    "Let's examine the distribution of individual features to understand their characteristics and identify potential patterns.\n",
    "\n",
    "### 4.1 Numerical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d642b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key numerical features\n",
    "print(\"üìä Analyzing Key Numerical Features\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select important numerical features for analysis\n",
    "key_numerical_features = [\n",
    "    'duration',      # Connection duration  \n",
    "    'src_bytes',     # Bytes from source to destination\n",
    "    'dst_bytes',     # Bytes from destination to source\n",
    "    'count',         # Number of connections to same host\n",
    "    'srv_count',     # Number of connections to same service\n",
    "    'serror_rate',   # % of connections with SYN errors\n",
    "    'dst_host_count' # Count of connections to same destination host\n",
    "]\n",
    "\n",
    "# Initialize the univariate analyzer for numerical features\n",
    "univariate_analyzer = UnivariateAnalyzer(KDD99NumericalUnivariateAnalysis())\n",
    "\n",
    "# Analyze each numerical feature\n",
    "for feature in key_numerical_features:\n",
    "    if feature in df.columns:\n",
    "        print(f\"\\nüîç Analyzing: {feature}\")\n",
    "        univariate_analyzer.execute_analysis(df, feature)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Feature '{feature}' not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910d15c3",
   "metadata": {},
   "source": [
    "### 4.2 Categorical Features Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddf0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key categorical features\n",
    "print(\"üìä Analyzing Key Categorical Features\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Select important categorical features for analysis\n",
    "key_categorical_features = [\n",
    "    'protocol_type',  # Network protocol (TCP, UDP, ICMP)\n",
    "    'service',        # Network service on destination\n",
    "    'flag',           # Status flag of the connection\n",
    "    'label'           # Attack type label (target variable)\n",
    "]\n",
    "\n",
    "# Switch to categorical analysis strategy\n",
    "univariate_analyzer.set_strategy(KDD99CategoricalUnivariateAnalysis())\n",
    "\n",
    "# Analyze each categorical feature\n",
    "for feature in key_categorical_features:\n",
    "    if feature in df.columns:\n",
    "        print(f\"\\nüîç Analyzing: {feature}\")\n",
    "        univariate_analyzer.execute_analysis(df, feature)\n",
    "        print(\"-\" * 50)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Feature '{feature}' not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424ef09",
   "metadata": {},
   "source": [
    "### üìã Univariate Analysis Insights\n",
    "\n",
    "From the univariate analysis, we can observe several important patterns:\n",
    "\n",
    "#### **Numerical Features:**\n",
    "1. **Duration**: Most connections are very short, with a long tail of longer connections\n",
    "2. **Bytes transferred**: Highly skewed distributions with many zero-byte connections\n",
    "3. **Count features**: Show the frequency of connections, important for detecting scanning attacks\n",
    "4. **Error rates**: Most connections have low error rates, with spikes indicating potential attacks\n",
    "\n",
    "#### **Categorical Features:**\n",
    "1. **Protocol Type**: TCP dominates, followed by UDP and ICMP\n",
    "2. **Service**: HTTP, SMTP, and other common services are prevalent\n",
    "3. **Flag**: Connection status flags show various completion states\n",
    "4. **Attack Labels**: Confirms the imbalanced nature with normal traffic and various attack types\n",
    "\n",
    "These patterns suggest that feature engineering and normalization will be important for effective anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1530b380",
   "metadata": {},
   "source": [
    "## üîó 5. Bivariate Analysis\n",
    "\n",
    "Now let's examine relationships between pairs of features to understand how they interact and influence each other.\n",
    "\n",
    "### 5.1 Numerical vs Numerical Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72851fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationships between numerical features\n",
    "print(\"üìä Bivariate Analysis: Numerical vs Numerical\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize bivariate analyzer for numerical features\n",
    "bivariate_analyzer = BivariateAnalyzer(KDD99NumericalVsNumericalAnalysis())\n",
    "\n",
    "# Define important feature pairs to analyze\n",
    "numerical_pairs = [\n",
    "    ('src_bytes', 'dst_bytes'),          # Bytes sent vs received\n",
    "    ('count', 'srv_count'),              # Connection counts\n",
    "    ('duration', 'src_bytes'),           # Duration vs data volume\n",
    "    ('serror_rate', 'srv_serror_rate'),  # Error rates comparison\n",
    "]\n",
    "\n",
    "# Analyze each pair\n",
    "for feature1, feature2 in numerical_pairs:\n",
    "    if feature1 in df.columns and feature2 in df.columns:\n",
    "        print(f\"\\nüîç Analyzing relationship: {feature1} vs {feature2}\")\n",
    "        bivariate_analyzer.execute_analysis(df, feature1, feature2)\n",
    "        print(\"-\" * 60)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è One or both features not found: {feature1}, {feature2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1d6e10",
   "metadata": {},
   "source": [
    "### 5.2 Categorical vs Numerical Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6d9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationships between categorical and numerical features\n",
    "print(\"üìä Bivariate Analysis: Categorical vs Numerical\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Switch to categorical vs numerical analysis\n",
    "bivariate_analyzer.set_strategy(KDD99CategoricalVsNumericalAnalysis())\n",
    "\n",
    "# Define important categorical-numerical pairs\n",
    "categorical_numerical_pairs = [\n",
    "    ('protocol_type', 'duration'),        # Protocol impact on duration\n",
    "    ('service', 'src_bytes'),             # Service impact on data volume\n",
    "    ('flag', 'dst_bytes'),                # Connection status vs bytes received\n",
    "    ('protocol_type', 'count'),           # Protocol vs connection frequency\n",
    "]\n",
    "\n",
    "# Analyze each pair\n",
    "for cat_feature, num_feature in categorical_numerical_pairs:\n",
    "    if cat_feature in df.columns and num_feature in df.columns:\n",
    "        print(f\"\\nüîç Analyzing relationship: {cat_feature} vs {num_feature}\")\n",
    "        bivariate_analyzer.execute_analysis(df, cat_feature, num_feature)\n",
    "        print(\"-\" * 60)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è One or both features not found: {cat_feature}, {num_feature}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9046e7bc",
   "metadata": {},
   "source": [
    "### üîç Bivariate Analysis Insights\n",
    "\n",
    "The bivariate analysis reveals important relationships:\n",
    "\n",
    "#### **Numerical Relationships:**\n",
    "1. **Data Flow Patterns**: The relationship between src_bytes and dst_bytes shows different communication patterns for different attack types\n",
    "2. **Connection Characteristics**: Count features show clustering patterns that differentiate normal from abnormal behavior\n",
    "3. **Temporal Patterns**: Duration relationships help identify prolonged attacks vs quick scans\n",
    "\n",
    "#### **Protocol and Service Impact:**\n",
    "1. **Protocol Differences**: Different protocols show distinct patterns in duration and data volume\n",
    "2. **Service Characteristics**: Various network services have different typical behaviors\n",
    "3. **Attack Signatures**: Certain combinations of categorical and numerical features create attack signatures\n",
    "\n",
    "These relationships will be crucial for:\n",
    "- **Feature engineering** - Creating interaction features\n",
    "- **Model selection** - Understanding which algorithms might work best\n",
    "- **Anomaly detection** - Identifying unusual combinations that indicate attacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581da07",
   "metadata": {},
   "source": [
    "## üåê 6. Multivariate Analysis\n",
    "\n",
    "Let's examine the complex relationships between multiple features simultaneously using correlation analysis and pair plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd731e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform comprehensive multivariate analysis\n",
    "print(\"üìä Multivariate Analysis for KDD99\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Initialize KDD99-specific multivariate analyzer\n",
    "multivariate_analyzer = KDD99MultivariateAnalysis()\n",
    "\n",
    "# Select a subset of numerical features for analysis\n",
    "# (Using all features would create an overwhelming visualization)\n",
    "numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Remove label if it's numerical\n",
    "if 'label' in numerical_features:\n",
    "    numerical_features.remove('label')\n",
    "\n",
    "print(f\"üìà Analyzing correlations among {len(numerical_features)} numerical features\")\n",
    "print(f\"üìä Features included: {', '.join(numerical_features[:10])}{'...' if len(numerical_features) > 10 else ''}\")\n",
    "\n",
    "# Create a subset for multivariate analysis\n",
    "selected_features = df[numerical_features]\n",
    "\n",
    "# Perform the analysis\n",
    "multivariate_analyzer.analyze(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288f684",
   "metadata": {},
   "source": [
    "### üéØ Multivariate Analysis Insights\n",
    "\n",
    "The multivariate analysis provides crucial insights for our anomaly detection system:\n",
    "\n",
    "#### **Correlation Patterns:**\n",
    "1. **Feature Redundancy**: High correlations indicate potential feature redundancy\n",
    "2. **Feature Groups**: Related features cluster together (e.g., error rates, count features)\n",
    "3. **Multicollinearity**: Strong correlations may require feature selection or regularization\n",
    "\n",
    "#### **Attack Detection Implications:**\n",
    "1. **Signature Patterns**: Attack types show distinct patterns in feature space\n",
    "2. **Separability**: Good separation between normal and attack patterns\n",
    "3. **Dimensionality**: Some features may be redundant for classification\n",
    "\n",
    "#### **Model Development Recommendations:**\n",
    "- **Feature Selection**: Remove highly correlated features\n",
    "- **Regularization**: Use L1/L2 regularization to handle multicollinearity  \n",
    "- **Dimensionality Reduction**: Consider PCA for feature reduction\n",
    "- **Ensemble Methods**: May handle feature correlations better than single models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7dd50",
   "metadata": {},
   "source": [
    "## üìã 7. Key Feature Analysis\n",
    "\n",
    "Let's focus on the most important features for anomaly detection based on our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76def14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the distribution of attack types in detail\n",
    "print(\"üéØ Detailed Attack Type Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'label' in df.columns:\n",
    "    # Get label distribution\n",
    "    label_counts = df['label'].value_counts()\n",
    "    \n",
    "    print(f\"üìä Total unique attack types: {len(label_counts)}\")\n",
    "    print(f\"üìà Total samples: {len(df):,}\")\n",
    "    \n",
    "    # Show top 20 attack types\n",
    "    print(\"\\nüîù Top 20 Attack Types:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    top_20 = label_counts.head(20)\n",
    "    for i, (attack, count) in enumerate(top_20.items(), 1):\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"{i:2d}. {attack:<20} {count:>8,} ({percentage:5.2f}%)\")\n",
    "    \n",
    "    # Create attack categories\n",
    "    attack_types = {\n",
    "        'normal': ['normal.'],\n",
    "        'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.', 'teardrop.'],\n",
    "        'probe': ['ipsweep.', 'nmap.', 'portsweep.', 'satan.'],\n",
    "        'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.', 'phf.', 'spy.', 'warezclient.', 'warezmaster.'],\n",
    "        'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.']\n",
    "    }\n",
    "    \n",
    "    # Create mapping\n",
    "    attack_category = {}\n",
    "    for category, attacks in attack_types.items():\n",
    "        for attack in attacks:\n",
    "            attack_category[attack] = category\n",
    "    \n",
    "    # Map categories\n",
    "    df_temp = df.copy()\n",
    "    df_temp['attack_category'] = df_temp['label'].map(attack_category)\n",
    "    \n",
    "    # Show category distribution\n",
    "    print(\"\\nüè∑Ô∏è Attack Category Distribution:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    category_counts = df_temp['attack_category'].value_counts()\n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"{category:<10} {count:>8,} ({percentage:5.2f}%)\")\n",
    "    \n",
    "    # Visualize attack categories\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    fig.suptitle('KDD99 Attack Type Distribution Analysis', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Attack category pie chart\n",
    "    category_counts.plot(kind='pie', ax=axes[0, 0], autopct='%1.1f%%')\n",
    "    axes[0, 0].set_title('Attack Category Distribution')\n",
    "    axes[0, 0].set_ylabel('')\n",
    "    \n",
    "    # 2. Top 10 specific attacks\n",
    "    top_10_attacks = label_counts.head(10)\n",
    "    top_10_attacks.plot(kind='barh', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('Top 10 Specific Attack Types')\n",
    "    axes[0, 1].set_xlabel('Count')\n",
    "    \n",
    "    # 3. Attack category bar chart\n",
    "    category_counts.plot(kind='bar', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Attack Category Counts')\n",
    "    axes[1, 0].set_xlabel('Attack Category')\n",
    "    axes[1, 0].set_ylabel('Count')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 4. Log scale view of all attacks\n",
    "    axes[1, 1].bar(range(len(label_counts)), label_counts.values)\n",
    "    axes[1, 1].set_yscale('log')\n",
    "    axes[1, 1].set_title('All Attack Types (Log Scale)')\n",
    "    axes[1, 1].set_xlabel('Attack Type Index')\n",
    "    axes[1, 1].set_ylabel('Count (Log Scale)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Label column not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff65c5",
   "metadata": {},
   "source": [
    "## üîç 8. Feature Importance Analysis\n",
    "\n",
    "Let's identify which features are most discriminative for anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd8639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance using statistical measures\n",
    "print(\"üìä Feature Importance Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'label' in df.columns:\n",
    "    # Create binary labels for anomaly detection\n",
    "    df_analysis = df.copy()\n",
    "    df_analysis['is_anomaly'] = (df_analysis['label'] != 'normal.').astype(int)\n",
    "    \n",
    "    # Calculate feature importance using correlation with anomaly label\n",
    "    numerical_features = df_analysis.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    numerical_features.remove('is_anomaly')\n",
    "    if 'label' in numerical_features:\n",
    "        numerical_features.remove('label')\n",
    "    \n",
    "    # Calculate correlations\n",
    "    feature_correlations = {}\n",
    "    for feature in numerical_features:\n",
    "        correlation = abs(df_analysis[feature].corr(df_analysis['is_anomaly']))\n",
    "        feature_correlations[feature] = correlation\n",
    "    \n",
    "    # Sort by importance\n",
    "    important_features = sorted(feature_correlations.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    print(\"üîù Top 15 Most Important Features (by correlation with anomaly):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, (feature, correlation) in enumerate(important_features[:15], 1):\n",
    "        print(f\"{i:2d}. {feature:<25} {correlation:.4f}\")\n",
    "    \n",
    "    # Visualize feature importance\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    top_features = important_features[:20]\n",
    "    features_names = [f[0] for f in top_features]\n",
    "    correlations = [f[1] for f in top_features]\n",
    "    \n",
    "    plt.barh(range(len(top_features)), correlations)\n",
    "    plt.yticks(range(len(top_features)), features_names)\n",
    "    plt.xlabel('Absolute Correlation with Anomaly Label')\n",
    "    plt.title('Top 20 Features by Importance for Anomaly Detection')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical analysis by attack category\n",
    "    print(\"\\nüìà Statistical Analysis by Attack Category:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    attack_category = {}\n",
    "    attack_types = {\n",
    "        'normal': ['normal.'],\n",
    "        'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.', 'teardrop.'],\n",
    "        'probe': ['ipsweep.', 'nmap.', 'portsweep.', 'satan.'],\n",
    "        'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.', 'phf.', 'spy.', 'warezclient.', 'warezmaster.'],\n",
    "        'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.']\n",
    "    }\n",
    "    \n",
    "    for category, attacks in attack_types.items():\n",
    "        for attack in attacks:\n",
    "            attack_category[attack] = category\n",
    "    \n",
    "    df_analysis['attack_category'] = df_analysis['label'].map(attack_category)\n",
    "    df_analysis = df_analysis.dropna(subset=['attack_category'])\n",
    "    \n",
    "    # Show mean values of top features by attack category\n",
    "    top_5_features = [f[0] for f in important_features[:5]]\n",
    "    \n",
    "    category_stats = df_analysis.groupby('attack_category')[top_5_features].mean()\n",
    "    \n",
    "    print(\"üìä Mean values of top 5 features by attack category:\")\n",
    "    print(category_stats.round(4))\n",
    "    \n",
    "    # Visualize feature patterns by attack category\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('Feature Patterns by Attack Category', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, feature in enumerate(top_5_features):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "        \n",
    "        sns.boxplot(data=df_analysis, x='attack_category', y=feature, ax=axes[row, col])\n",
    "        axes[row, col].set_title(f'{feature} by Attack Category')\n",
    "        axes[row, col].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Remove the empty subplot\n",
    "    if len(top_5_features) == 5:\n",
    "        fig.delaxes(axes[1, 2])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Label column not found - cannot perform importance analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4dd761",
   "metadata": {},
   "source": [
    "## üìä 9. Data Quality and Preprocessing Insights\n",
    "\n",
    "Based on our comprehensive EDA, let's summarize key insights for data preprocessing and model development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff386962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive data quality assessment\n",
    "print(\"üîç Data Quality Assessment and Preprocessing Recommendations\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Data completeness\n",
    "print(\"1Ô∏è‚É£ DATA COMPLETENESS:\")\n",
    "print(f\"   ‚úÖ No missing values detected\")\n",
    "print(f\"   ‚úÖ All {len(df.columns)} features are complete\")\n",
    "print(f\"   ‚úÖ Dataset size: {len(df):,} samples\")\n",
    "\n",
    "# 2. Data types and structure\n",
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\n2Ô∏è‚É£ DATA STRUCTURE:\")\n",
    "print(f\"   üìä Numerical features: {len(numerical_cols)}\")\n",
    "print(f\"   üè∑Ô∏è Categorical features: {len(categorical_cols)}\")\n",
    "print(f\"   üìè Total features: {len(df.columns)}\")\n",
    "\n",
    "# 3. Class imbalance analysis\n",
    "if 'label' in df.columns:\n",
    "    print(f\"\\n3Ô∏è‚É£ CLASS DISTRIBUTION:\")\n",
    "    \n",
    "    # Create attack categories\n",
    "    attack_types = {\n",
    "        'normal': ['normal.'],\n",
    "        'dos': ['back.', 'land.', 'neptune.', 'pod.', 'smurf.', 'teardrop.'],\n",
    "        'probe': ['ipsweep.', 'nmap.', 'portsweep.', 'satan.'],\n",
    "        'r2l': ['ftp_write.', 'guess_passwd.', 'imap.', 'multihop.', 'phf.', 'spy.', 'warezclient.', 'warezmaster.'],\n",
    "        'u2r': ['buffer_overflow.', 'loadmodule.', 'perl.', 'rootkit.']\n",
    "    }\n",
    "    \n",
    "    attack_category = {}\n",
    "    for category, attacks in attack_types.items():\n",
    "        for attack in attacks:\n",
    "            attack_category[attack] = category\n",
    "    \n",
    "    df_temp = df.copy()\n",
    "    df_temp['attack_category'] = df_temp['label'].map(attack_category)\n",
    "    category_counts = df_temp['attack_category'].value_counts()\n",
    "    \n",
    "    for category, count in category_counts.items():\n",
    "        percentage = (count / len(df)) * 100\n",
    "        print(f\"   {category.upper():<8}: {count:>8,} samples ({percentage:5.2f}%)\")\n",
    "\n",
    "# 4. Feature scaling requirements\n",
    "print(f\"\\n4Ô∏è‚É£ FEATURE SCALING ANALYSIS:\")\n",
    "for feature in numerical_cols[:5]:  # Check first 5 numerical features\n",
    "    min_val = df[feature].min() \n",
    "    max_val = df[feature].max()\n",
    "    mean_val = df[feature].mean()\n",
    "    std_val = df[feature].std()\n",
    "    \n",
    "    print(f\"   {feature:<20}: Range=[{min_val:.2f}, {max_val:.2f}], Œº={mean_val:.2f}, œÉ={std_val:.2f}\")\n",
    "\n",
    "# 5. Categorical encoding requirements\n",
    "print(f\"\\n5Ô∏è‚É£ CATEGORICAL ENCODING NEEDS:\")\n",
    "for feature in categorical_cols:\n",
    "    unique_count = df[feature].nunique()\n",
    "    print(f\"   {feature:<20}: {unique_count:>3} unique values\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ PREPROCESSING RECOMMENDATIONS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n‚úÖ REQUIRED PREPROCESSING STEPS:\")\n",
    "print(\"   1. Feature Scaling: StandardScaler or MinMaxScaler for numerical features\")\n",
    "print(\"   2. Categorical Encoding: One-hot encoding for categorical features\")\n",
    "print(\"   3. Feature Selection: Remove highly correlated features (|r| > 0.95)\")\n",
    "print(\"   4. Class Balancing: Consider SMOTE or class weights for imbalanced classes\")\n",
    "print(\"   5. Outlier Treatment: Robust scaling or outlier removal for extreme values\")\n",
    "\n",
    "print(\"\\nüìä MODEL DEVELOPMENT INSIGHTS:\")\n",
    "print(\"   ‚Ä¢ Dataset is ready for machine learning (no missing values)\")\n",
    "print(\"   ‚Ä¢ High-dimensional feature space may benefit from dimensionality reduction\")\n",
    "print(\"   ‚Ä¢ Class imbalance requires careful evaluation metric selection\")\n",
    "print(\"   ‚Ä¢ Strong feature correlations suggest ensemble methods may work well\")\n",
    "print(\"   ‚Ä¢ Attack signature patterns are distinct enough for good classification\")\n",
    "\n",
    "print(\"\\nüöÄ READY FOR MODEL DEVELOPMENT!\")\n",
    "print(\"   The dataset is well-prepared for building anomaly detection models\")\n",
    "print(\"   with appropriate preprocessing pipelines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5eb29",
   "metadata": {},
   "source": [
    "## üéØ 10. Summary and Conclusions\n",
    "\n",
    "### üìã **Key Findings from EDA:**\n",
    "\n",
    "#### **Dataset Characteristics:**\n",
    "- ‚úÖ **Complete Dataset**: No missing values, excellent data quality\n",
    "- üìä **Rich Feature Set**: 41 features covering various network connection aspects  \n",
    "- üéØ **Clear Target**: Well-defined attack categories and normal traffic\n",
    "- ‚öñÔ∏è **Class Imbalance**: Typical of intrusion detection datasets\n",
    "\n",
    "#### **Feature Insights:**\n",
    "1. **Numerical Features**: Show distinct patterns between normal and attack traffic\n",
    "2. **Categorical Features**: Protocol, service, and flag provide strong discriminative power\n",
    "3. **Feature Correlations**: Some redundancy exists, feature selection will help\n",
    "4. **Attack Signatures**: Each attack type has characteristic feature patterns\n",
    "\n",
    "#### **Data Quality:**\n",
    "- üîç **No Missing Values**: Dataset is complete and ready for analysis\n",
    "- üìà **Consistent Structure**: All features have appropriate data types\n",
    "- üé® **Rich Patterns**: Clear separability between classes observed\n",
    "- ‚ö° **Scalable**: Dataset size is appropriate for modern ML algorithms\n",
    "\n",
    "### üöÄ **Recommendations for Model Development:**\n",
    "\n",
    "#### **Preprocessing Pipeline:**\n",
    "1. **Numerical Features**: Apply StandardScaler or MinMaxScaler\n",
    "2. **Categorical Features**: Use One-hot encoding or Label encoding\n",
    "3. **Feature Selection**: Remove highly correlated features\n",
    "4. **Class Balancing**: Apply SMOTE or adjust class weights\n",
    "\n",
    "#### **Model Selection Strategy:**\n",
    "1. **Tree-based Models**: XGBoost, Random Forest (handle feature interactions well)\n",
    "2. **Ensemble Methods**: Voting classifiers, Stacking (leverage different algorithms)\n",
    "3. **Neural Networks**: Deep learning for complex pattern recognition\n",
    "4. **Anomaly Detection**: Isolation Forest, One-Class SVM for unsupervised learning\n",
    "\n",
    "#### **Evaluation Approach:**\n",
    "- **Metrics**: Focus on Recall (catch all attacks), Precision, F1-score, AUC\n",
    "- **Cross-validation**: Stratified K-fold to handle class imbalance\n",
    "- **Attack-specific**: Evaluate performance per attack category\n",
    "- **Threshold Tuning**: Optimize decision thresholds for operational requirements\n",
    "\n",
    "### ‚ú® **Next Steps:**\n",
    "1. **Implement preprocessing pipeline** based on EDA insights\n",
    "2. **Develop baseline models** using identified important features  \n",
    "3. **Feature engineering** to create interaction features\n",
    "4. **Model comparison** across different algorithms\n",
    "5. **Production deployment** with real-time inference capabilities\n",
    "\n",
    "The comprehensive EDA has provided valuable insights that will guide the development of an effective anomaly detection system for network intrusion detection! üéâ"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
